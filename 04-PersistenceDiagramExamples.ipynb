{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Persistence Diagrams\n",
    "\n",
    "We now understand the full mathematical pipeline for creating a persistence diagram from a dataset:\n",
    "\n",
    "Dataset $\\to$ Filtered Simplicial Complex $\\to$ Persistence Module $\\to$ Persistence Diagram\n",
    "\n",
    " - The first step is accomplished by, for example, assigning a sequence of Vietoris-Rips complexes to point cloud data. \n",
    " - The second step involves computing the $k$th homology vector space of each Vietoris-Rips complex. \n",
    " - Finally, the last step follows from the interval decomposition we get from the Fundamental Theorem of Persistent Homology.\n",
    " \n",
    "In this notebook, we will look at a few more examples of persistence diagrams generated from toy datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import gudhi as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some 2-Dimensional Datasets\n",
    "\n",
    "Let's look at a dataset consisting of a pair of circles in the plane. We can parameterize our example by including a variable radius and offset parameter. One circle will always be radius 1, centered at the origin. The other circle will be variable. We can also include variable noise terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circle_data(radius, x_offset, noise1 = 0.5, noise2 = 0.5, num_points1 = 50, num_points2 = 50):\n",
    "    \n",
    "    A = np.random.multivariate_normal([0,0],np.array([[1,0],[0,1]]),size = num_points1)\n",
    "    A = A.T/np.linalg.norm(A,axis = 1)\n",
    "    A = A.T + noise1*np.random.rand(num_points1,2)\n",
    "\n",
    "    B = np.random.multivariate_normal([0,0],np.array([[1,0],[0,1]]),size = num_points2)\n",
    "    B = radius*B.T/np.linalg.norm(B,axis = 1)\n",
    "    B = B.T + noise2*np.random.rand(num_points2,2) + [x_offset,0]\n",
    "\n",
    "    X = np.concatenate((A,B))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = create_circle_data(1,2)\n",
    "\n",
    "plt.plot(X[:,0],X[:,1],'o')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week we introduced the `gudhi` package for computing persistence diagrams. The following function will take a point cloud and produce either barcodes or persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_persistent_homology(X, style = 'barcodes', max_dimension = 2):\n",
    "\n",
    "    \"\"\"\n",
    "    In: X is a Euclidean point cloud of size [num_points,dimension]\n",
    "        style = 'barcodes' or 'diagrams'\n",
    "        max_dimension = highest dimensional skeleton of the VR complex to compute. Highest degree\n",
    "        persistent homology will be one less than this.\n",
    "    Out: plots either persistence barcodes or persistence diagrams\n",
    "    \"\"\"\n",
    "    \n",
    "    D = pairwise_distances(X)\n",
    "    skeleton = gd.RipsComplex(distance_matrix = D, max_edge_length = 10) \n",
    "    Rips_complex = skeleton.create_simplex_tree(max_dimension = max_dimension)\n",
    "    BarCodes = Rips_complex.persistence()\n",
    "\n",
    "    if style == 'barcodes':\n",
    "        for dim in range(max_dimension):\n",
    "            print('Dimension',dim)\n",
    "            plt.figure()\n",
    "            gd.plot_persistence_barcode([bar for bar in BarCodes if bar[0] == dim])\n",
    "            plt.show()\n",
    "    elif style == 'diagrams':\n",
    "        plt.figure()\n",
    "        gd.plot_persistence_diagram(BarCodes)\n",
    "        plt.show()\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_persistent_homology(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_persistent_homology(X, style = 'diagrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try this on different point clouds and see if the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick parameters:\n",
    "radius = 2\n",
    "x_offset = 3\n",
    "noise1 = 10\n",
    "noise2 = 3\n",
    "num_points1 = 50\n",
    "num_points2 = 50\n",
    "\n",
    "X = create_circle_data(radius,x_offset,noise1 = noise1, noise2 = noise2, num_points1 = num_points1, num_points2 = num_points2)\n",
    "\n",
    "plt.plot(X[:,0],X[:,1],'o')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "visualize_persistent_homology(X)\n",
    "\n",
    "visualize_persistent_homology(X, style = 'diagrams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Dimensional Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can look at some simple 3-dimensional point clouds. We'll start with a sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to sample randomly from a sphere\n",
    "def sample_spherical(npoints, ndim=3):\n",
    "    sample = np.random.randn(ndim, npoints)\n",
    "    sample /= np.linalg.norm(sample, axis=0)\n",
    "    sample = sample.T\n",
    "    return sample\n",
    "\n",
    "# Randomly sample from a sphere with added noise\n",
    "def noisy_sample_spherical(npoints, ndim, noise_level = 0.01):\n",
    "    sphere = sample_spherical(npoints, ndim)\n",
    "    noise = np.random.multivariate_normal(ndim*[0], noise_level*np.eye(ndim), npoints)\n",
    "    sample = sphere + noise\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = noisy_sample_spherical(200,3,noise_level = .001)\n",
    "# Generate the noisy circle.\n",
    "\n",
    "# Plot the data as a scatter plot.\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.gca(projection='3d', adjustable='box')\n",
    "ax.scatter(data[:,0],data[:,1],data[:,2], c='b', marker='o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we'd like to look at higher dimensional homology. Unfortunately, `gudhi` is a bit slow for computing higher dimensional persistent homology (I believe that it has some ways to sparsify simplicial complexes, which may make it faster). You can try running the function we created above, but it will take quite a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_persistent_homology(data, max_dimension=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead use a different TDA package which is optimized specifically to handle Vietoris-Rips persistent homology on point clouds. The algorithm is called `ripser`. To install `ripser` as well as the `persim` package (which includes some visualization tools, plus some functions for vectorizing persistence diagrams that we will discuss later), you can install the `scikit-tda` package: see https://scikit-tda.org/index.html. \n",
    "\n",
    "**Disclaimer:** I've seen people have trouble installing these packages, in particular on Windows machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser\n",
    "from persim import plot_diagrams "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ripser` does the job a lot more quickly, but is still not super fast if we compute higher dimensional persistent homology on large point clouds. You can experiment with parameters here to see how far you can push this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dgms = ripser(data, maxdim=2)['dgms']\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plot_diagrams(dgms, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following point cloud lies on the surface of a donut in 3-dimensional space (called a *torus*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 300\n",
    "r = 5\n",
    "R = 10\n",
    "\n",
    "theta = 2*np.pi*np.random.rand(N)\n",
    "phi = 2*np.pi*np.random.rand(N)\n",
    "X = (R + r * np.cos(phi)) * np.cos(theta)\n",
    "Y = (R + r * np.cos(phi)) * np.sin(theta) \n",
    "Z = r *  np.sin(phi)\n",
    "pointCloud = np.append(X.reshape(N,1),Y.reshape(N,1),axis =1)\n",
    "pointCloud = np.append(pointCloud,Z.reshape(N,1), axis = 1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (6,6))\n",
    "ax = fig.gca(projection='3d', adjustable='box')\n",
    "ax.scatter(pointCloud[:,0],pointCloud[:,1],pointCloud[:,2], c='b', marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dgms = ripser(pointCloud, maxdim=2)['dgms']\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plot_diagrams(dgms, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When sampling a torus, we need to sample fairly densely to get a strong topological signal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
